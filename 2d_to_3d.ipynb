{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcee372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2 as cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import math\n",
    "from scipy.signal import medfilt # for median smoothing\n",
    "from scipy.signal import savgol_filter # for Savitzky-Golay filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be850f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.4304873e-01  1.6235021e-01  1.6325009e-04  8.3221312e-05\n",
      "   1.7859804e-02  1.9692841e-01  5.7774126e-03  9.8922580e-02]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[395.60663,   0.     , 316.72214],\n",
       "       [  0.     , 395.56976, 259.20657],\n",
       "       [  0.     ,   0.     ,   1.     ]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_coefs = np.asarray([[-0.2430487205352619,\n",
    "                          0.1623502095383119,\n",
    "                          0.0001632500987373085,\n",
    "                          8.322130878440475e-05,\n",
    "                          0.017859803336754784,\n",
    "                          0.1969284124154412,\n",
    "                          0.00577741263771627,\n",
    "                          0.09892258337410824]], dtype = np.float32)\n",
    "camera_matrix = np.asarray([[395.60662814306596, 0.0, 316.72212558212516],\n",
    "                            [0.0, 395.56975615889445, 259.206579702132],\n",
    "                            [0.0, 0.0, 1.0]], dtype = np.float32)\n",
    "print(dist_coefs)\n",
    "camera_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c0cab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IJD helper functions\n",
    "# define smoothing function\n",
    "def smooth(arr):\n",
    "    return medfilt(arr, kernel_size = 9)#medfilt is imported as is from scipy.signal\n",
    "# For writing out timestamps as elapsed seconds\n",
    "def get_elapsed_seconds(time_col):\n",
    "    time_col_copy = time_col.copy()\n",
    "    #t = [re.sub('/1000', '', t) for t in time_col_copy]\n",
    "    #t = [re.split(':', t) for t in t]\n",
    "    t = [re.split('\\W+', ti) for ti in time_col_copy]\n",
    "    out = []\n",
    "    for x in t:\n",
    "        d, h, m, s, ms, _ = [float(y) for y in x]\n",
    "        out.append(np.sum([h*3600, m*60, s, ms/1000]))\n",
    "    return out\n",
    "# test it:\n",
    "# time_col_test = test['sceneQTtime(d:h:m:s.tv/ts)'].values\n",
    "# get_elapsed_seconds(time_col_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1f6c078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the code provided by pupil labs tutorial (not what we will use)\n",
    "def unprojectPoints(pts_2d, K, D, use_distortion=True, normalize=False):\n",
    "        \"\"\"\n",
    "        Undistorts points according to the camera model.\n",
    "        :param pts_2d, shape: Nx2\n",
    "        :return: Array of unprojected 3d points, shape: Nx3\n",
    "        \"\"\"\n",
    "        pts_2d = np.array(pts_2d, dtype=np.float32)\n",
    "\n",
    "        # Delete any posibly wrong 3rd dimension\n",
    "        if pts_2d.ndim == 1 or pts_2d.ndim == 3:\n",
    "            pts_2d = pts_2d.reshape((-1, 2))\n",
    "\n",
    "        # Add third dimension the way cv2 wants it\n",
    "        if pts_2d.ndim == 2:\n",
    "            pts_2d = pts_2d.reshape((-1, 1, 2))\n",
    "\n",
    "        if use_distortion:\n",
    "            _D = D\n",
    "        else:\n",
    "            _D = np.asarray([[0.0, 0.0, 0.0, 0.0, 0.0]])\n",
    "\n",
    "        pts_2d_undist = cv2.undistortPoints(pts_2d, K, _D)\n",
    "\n",
    "        pts_3d = cv2.convertPointsToHomogeneous(pts_2d_undist)\n",
    "        pts_3d.shape = -1, 3\n",
    "\n",
    "        if normalize:\n",
    "            pts_3d /= np.linalg.norm(pts_3d, axis=1)[:, np.newaxis]\n",
    "\n",
    "        return pts_3d\n",
    "\n",
    "# Unprojecting an image\n",
    "def undistort_img(img, K, D):\n",
    "        \"\"\"\n",
    "        Undistortes an image based on the camera model.\n",
    "        :param img: Distorted input image\n",
    "        :return: Undistorted image\n",
    "        \"\"\"\n",
    "        undist_img = cv2.undistort(img, K, D)\n",
    "        return undist_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc49ab21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>c_clean1_noisy0</th>\n",
       "      <th>c_quality_1low_to_3high</th>\n",
       "      <th>c_comments</th>\n",
       "      <th>c_twelve_segments</th>\n",
       "      <th>c_good_start_sec</th>\n",
       "      <th>c_good_end_sec</th>\n",
       "      <th>p_clean1_noisy0</th>\n",
       "      <th>p_quality_1low_to_3high</th>\n",
       "      <th>p_comments</th>\n",
       "      <th>p_twelve_segments</th>\n",
       "      <th>p_good_start_sec</th>\n",
       "      <th>p_good_end_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__20180508_20241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__20180510_20142</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>TAKE ENTIRE RECORDING; decent quality</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>522.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__20180510_20427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Noisy at beginning</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__20180604_20582</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lot of dropout; too much noise in baseline</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__20180607_21633</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>lot of dropout</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1094.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>__20180622_23512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>__20180628_21840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>lot of dropout</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>__20180711_21933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>small amount at start is okay</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>__20180718_21501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>better at end</td>\n",
       "      <td>2.5</td>\n",
       "      <td>94.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.0</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>__20180725_21960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>too much fixation noise</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no parent data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            subject  c_clean1_noisy0  c_quality_1low_to_3high  \\\n",
       "0  __20180508_20241              0.0                      1.5   \n",
       "1  __20180510_20142              1.0                      2.5   \n",
       "2  __20180510_20427              1.0                      2.0   \n",
       "3  __20180604_20582              0.0                      1.0   \n",
       "4  __20180607_21633              1.0                      2.0   \n",
       "5  __20180622_23512              0.0                      1.0   \n",
       "6  __20180628_21840              0.0                      2.0   \n",
       "7  __20180711_21933              0.0                      1.5   \n",
       "8  __20180718_21501              1.0                      2.5   \n",
       "9  __20180725_21960              0.0                      1.5   \n",
       "\n",
       "                                   c_comments  c_twelve_segments  \\\n",
       "0                                         NaN                1.0   \n",
       "1       TAKE ENTIRE RECORDING; decent quality                2.5   \n",
       "2                          Noisy at beginning                2.5   \n",
       "3  lot of dropout; too much noise in baseline                1.0   \n",
       "4                              lot of dropout                1.0   \n",
       "5                                         NaN                1.0   \n",
       "6                              lot of dropout                1.0   \n",
       "7               small amount at start is okay                2.5   \n",
       "8                               better at end                2.5   \n",
       "9                     too much fixation noise                1.0   \n",
       "\n",
       "   c_good_start_sec  c_good_end_sec  p_clean1_noisy0  p_quality_1low_to_3high  \\\n",
       "0               NaN             NaN              NaN                      NaN   \n",
       "1               0.0          1242.0              NaN                      NaN   \n",
       "2               0.0           402.0              NaN                      NaN   \n",
       "3               NaN             NaN              NaN                      NaN   \n",
       "4               NaN             NaN              NaN                      NaN   \n",
       "5               NaN             NaN              NaN                      NaN   \n",
       "6               NaN             NaN              NaN                      NaN   \n",
       "7               0.0           282.0              NaN                      NaN   \n",
       "8              94.0           322.0              NaN                      NaN   \n",
       "9               NaN             NaN              NaN                      NaN   \n",
       "\n",
       "       p_comments p_twelve_segments  p_good_start_sec  p_good_end_sec  \n",
       "0             NaN                 1               NaN             NaN  \n",
       "1             NaN               NaN               0.0           522.0  \n",
       "2             NaN               NaN               0.0           304.0  \n",
       "3             NaN               NaN               0.0           520.0  \n",
       "4             NaN               NaN             110.0          1094.0  \n",
       "5             NaN                 1               NaN             NaN  \n",
       "6             NaN                 1               NaN             NaN  \n",
       "7             NaN                 1               NaN             NaN  \n",
       "8             NaN               NaN              62.0           168.0  \n",
       "9  no parent data               NaN               NaN             NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv('../noise_ratings.csv', encoding='mac_roman')\n",
    "ratings.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a8a9e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__20180508_20241\n"
     ]
    }
   ],
   "source": [
    "#subject_paths = glob.glob('M:/experiment_15/included/__20*')\n",
    "#subjects = [re.search('__[0-9]+_[0-9]+', x).group() for x in subject_paths]\n",
    "#subjects\n",
    "subject_paths = glob.glob('../included/*')\n",
    "subjects = [re.search('__[0-9]+_[0-9]+', x).group() for x in subject_paths]\n",
    "for i in subjects[0:1]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ad48d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@5.666] global /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('M:/experiment_15/included/__20180817_21699/cam07_frames_p/img_600.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sj/yj176mhx02n6shs20d029st40000gn/T/ipykernel_84787/1747753371.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#impath = '/Volumes/multiwork/experiment_15/included/__20180817_21699/cam07_frames_p/img_600.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "#impath = 'C:bell/multiwork/experiment_15/included/__20180817_21699/cam07_frames_p/img_600.jpg'\n",
    "impath = 'M:/experiment_15/included/__20180817_21699/cam07_frames_p/img_600.jpg'\n",
    "#impath = '/Volumes/multiwork/experiment_15/included/__20180817_21699/cam07_frames_p/img_600.jpg'\n",
    "I = cv2.imread(impath)\n",
    "I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc56562",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the image with matplotlib\n",
    "plt.imshow(I)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9243a6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undistort the image and plot again\n",
    "I_undist = undistort_img(I, camera_matrix, dist_coefs)\n",
    "plt.imshow(I_undist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4acf2d3",
   "metadata": {},
   "source": [
    "The estimated intrinsics are compatible with this camera, evidenced by the fact that the undistorted image shows less radial warping (less bending of straight lines, such as the puzzle-piece floor mat shown in the experiment room). The same intrinsics can thus be used to undistort 2D points back into 3D gaze vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cb2d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datpath= 'C:bell/multiwork/experiment_15/included/__20180817_21699/supporting_files/child_eye.txt'\n",
    "datpath= 'M:/experiment_15/included/__20180510_20142/supporting_files/child_eye.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93018c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(datpath, header=4, sep=' ', index_col=False)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f361e731",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.porX[np.logical_and(test.porX < 2000, test.porX > -2000)].hist(bins=np.arange(-1900, 1900, 200))\n",
    "test.porY[np.logical_and(test.porY < 2000, test.porY > -2000)].hist(bins=np.arange(-1900, 1900, 200))\n",
    "#test.porX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1f888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(1, 10,1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d31b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test undistoring the points\n",
    "# First keep track of rows where either x or y coordinate is -1000 (missing value)\n",
    "good_X_mask = test.pupilX.values >= 0\n",
    "good_Y_mask = test.pupilY.values >= 0\n",
    "dropout_mask = good_X_mask.astype('int') + good_Y_mask.astype('int')\n",
    "dropout_mask = dropout_mask <= 1 # Where either x or y is missing\n",
    "# Replace these missing points with nan for now in an Nx2 array with x,y coords\n",
    "pts_2d = test.loc[:, ['porX', 'porY']].replace(-1000, np.nan).to_numpy()\n",
    "print('array of x, y coordinates:\\n'); print(pts_2d)\n",
    "# Unproject the points using the function defined above\n",
    "# (It's just a wrapper for opencv undistortPoints)\n",
    "pts_3d = unprojectPoints(pts_2d, camera_matrix, dist_coefs, normalize=False)\n",
    "pts_3d[dropout_mask, ] = np.nan\n",
    "print(pts_3d.shape) # the full array size (should be same as origainl)\n",
    "print(pts_3d[dropout_mask == False, :].shape) # number of rows without nan\n",
    "pts_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589e7a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking that the results are comparable to using opencv directly\n",
    "pts_test = cv2.undistortPoints(pts_2d, camera_matrix, dist_coefs)\n",
    "pts_test_2 = cv2.convertPointsToHomogeneous(pts_test)\n",
    "print(pts_test)\n",
    "print(pts_test_2)\n",
    "pts_test_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93901639",
   "metadata": {},
   "source": [
    "The next few chunks are taken from a pupil labs tutorial for computing angular velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04ec36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to facilitate computation of velocity\n",
    "# And for plotting:\n",
    "def sphere_pos_over_time(ts, data, unit=\"radians\"):\n",
    "    for key, values in data.items():\n",
    "        sns.lineplot(x=ts, y=values, label=key)\n",
    "    plt.xlabel(\"time [sec]\")\n",
    "    plt.ylabel(unit)\n",
    "    plt.legend()\n",
    "\n",
    "def cart_to_spherical(x, y, z, apply_rad2deg=False):\n",
    "    # convert to spherical coordinates\n",
    "    # source: http://stackoverflow.com/questions/4116658/faster-numpy-cartesian-to-spherical-coordinate-conversion\n",
    "    #x = data.gaze_point_3d_x\n",
    "    #y = data.gaze_point_3d_y\n",
    "    #z = data.gaze_point_3d_z\n",
    "    r = np.sqrt(x ** 2 + y ** 2 + z ** 2)\n",
    "    theta = np.arccos(y / r)  # for elevation angle defined from Z-axis down\n",
    "    psi = np.arctan2(z, x)\n",
    "    \n",
    "    if apply_rad2deg:\n",
    "        theta = np.rad2deg(theta)\n",
    "        psi = np.rad2deg(psi)\n",
    "    \n",
    "    return r, theta, psi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539ee7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate velocity\n",
    "timestamp = test.recordFrameCount / test.avg_fps\n",
    "r, theta, psi = cart_to_spherical(pts_3d[:, 0], pts_3d[:, 1], pts_3d[:, 2], apply_rad2deg=True)\n",
    "squared_theta_diff = np.diff(theta) ** 2\n",
    "squared_psi_diff = np.diff(psi) ** 2\n",
    "deg_diff = np.sqrt(squared_theta_diff + squared_psi_diff)\n",
    "ts_diff = np.diff(timestamp)\n",
    "deg_per_sec = deg_diff / ts_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca764776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot velocity trace\n",
    "time = timestamp[:-1] - timestamp[0]\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sphere_pos_over_time(time[(time > 486) & (time < 496)], \n",
    "                     {\"gaze velocity\": deg_per_sec[(time > 486) & (time < 496)]}, unit=\"deg/sec\")\n",
    "plt.title(\"Gaze velocity over time\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(deg_per_sec, bins=np.logspace(-1, np.log10(500), 50))\n",
    "plt.title(\"Gaze velocity histogram\")\n",
    "plt.xlabel(\"Gaze velocity [deg/sec]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72db270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And for angular accel.\n",
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sphere_pos_over_time(time[(time > 486) & (time < 496)], \n",
    "                     {\"gaze velocity\": np.append(np.diff(deg_per_sec[(time > 486) & (time < 496)]), 0)}, unit=\"deg/sec\")\n",
    "plt.title(\"Gaze Acceleration over time\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(deg_per_sec, bins=np.logspace(-1, np.log10(500), 50))\n",
    "plt.title(\"Gaze velocity histogram\")\n",
    "plt.xlabel(\"Gaze velocity [deg/sec]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb674cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same plots for non-normalized xyz\n",
    "pts_3d = unprojectPoints(pts_2d, camera_matrix, dist_coefs, normalize=True)\n",
    "pts_3d[dropout_mask, ] = np.nan\n",
    "# Calculate velocity\n",
    "timestamp = test.recordFrameCount / test.avg_fps\n",
    "r, theta, psi = cart_to_spherical(pts_3d[:, 0], pts_3d[:, 1], pts_3d[:, 2], apply_rad2deg=True)\n",
    "squared_theta_diff = np.diff(theta) ** 2\n",
    "squared_psi_diff = np.diff(psi) ** 2\n",
    "deg_diff = np.sqrt(squared_theta_diff + squared_psi_diff)\n",
    "ts_diff = np.diff(timestamp)\n",
    "nonorm_deg_per_sec = deg_diff / ts_diff # THIS VARIABLE HAS NEW NAME\n",
    "#Plot\n",
    "time = timestamp[:-1] - timestamp[0]\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sphere_pos_over_time(time[(time > 486) & (time < 496)], \n",
    "                     {\"gaze velocity\": nonorm_deg_per_sec[(time > 486) & (time < 496)]}, unit=\"deg/sec\")\n",
    "plt.title(\"Gaze velocity over time\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(nonorm_deg_per_sec, bins=np.logspace(-1, np.log10(500), 50))\n",
    "plt.title(\"Gaze velocity histogram\")\n",
    "plt.xlabel(\"Gaze velocity [deg/sec]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b517f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through participants and write out the 3D data as a csv for each\n",
    "for i in subjects:\n",
    "    datpath=f\"G:/My Drive/UT/DIL/Research/EyeTrack/experiment_15/included/{i}/data/child_eye.txt\"\n",
    "    outpath=f\"G:/My Drive/UT/DIL/Research/EyeTrack/experiment_15/included/{i}/data/pts_3d_norm.csv\"\n",
    "    # Read in the child_eye.txt\n",
    "    df = pd.read_csv(datpath, header=4, sep=' ', index_col=False)\n",
    "    good_X_mask = df.pupilX.values >= 0\n",
    "    good_Y_mask = df.pupilY.values >= 0\n",
    "    dropout_mask = good_X_mask.astype('int') + good_Y_mask.astype('int')\n",
    "    dropout_mask = dropout_mask <= 1 # Where either x or y is missing\n",
    "    # Replace these missing points with nan for now in an Nx2 array with x,y coords\n",
    "    pts_2d = df.loc[:, ['pupilX', 'pupilY']].replace(-1000, np.nan).to_numpy()\n",
    "    pts_3d = unprojectPoints(pts_2d, camera_matrix, dist_coefs, normalize=True)\n",
    "    pts_3d[dropout_mask, ] = np.nan\n",
    "    pd.DataFrame(pts_3d).to_csv(outpath,  header = ['x', 'y', 'z'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81dfb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out a one-column data frame of timestamps\n",
    "for i in subjects:\n",
    "    datpath=f\"G:/My Drive/UT/DIL/Research/EyeTrack/experiment_15/included/{i}/data/child_eye.txt\"\n",
    "    outpath=f\"G:/My Drive/UT/DIL/Research/EyeTrack/experiment_15/included/{i}/data/child_eye_timestamps.csv\"\n",
    "    # Read in the child_eye.txt\n",
    "    df = pd.read_csv(datpath, header=4, sep=' ', index_col=False)\n",
    "    times = df.loc[:, ['recordFrameCount', 'avg_fps']]\n",
    "    times.to_csv(outpath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea1e0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in subjects:\n",
    "    datpath=f\"G:/My Drive/UT/DIL/Research/EyeTrack/experiment_15/included/{i}/data/child_eye.txt\"\n",
    "    outpath=f\"G:/My Drive/UT/DIL/Research/EyeTrack/experiment_15/included/{i}/data/child_eye_elapsed-seconds.csv\"\n",
    "    # Read in the child_eye.txt\n",
    "    df = pd.read_csv(datpath, header=4, sep=' ', index_col=False)\n",
    "    times = df.loc[:, ['recordFrameCount', 'avg_fps']]\n",
    "    times['elapsed_seconds'] = get_elapsed_seconds(df['sceneQTtime(d:h:m:s.tv/ts)'].values)\n",
    "    times.to_csv(outpath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d060b08",
   "metadata": {},
   "source": [
    "This is our implementation, using a different computation of velocity. Additionally, we compute accel. and write out a data frame with timestamps, projected x, y, and z data, as well as veloc. and accel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a993a251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FRAME_PER_SEC = 30\n",
    "#sec_per_frame = 1/FRAME_PER_SEC\n",
    "# Write out a data frame with x, y, z, frame number, avg_fps, and elapsed time, velocity and accel.\n",
    "for i in subjects:\n",
    "    datpath=f\"G:/My Drive/UT/DIL/Research/EyeTrack/experiment_15/included/{i}/data/child_eye.txt\"\n",
    "    outpath=f\"G:/My Drive/UT/DIL/Research/EyeTrack/experiment_15/included/{i}/data/gaze_data_3dnormed_timestamped.csv\"\n",
    "    # Read in the child_eye.txt\n",
    "    df = pd.read_csv(datpath, header=4, sep=' ', index_col=False)\n",
    "    good_X_mask = df.pupilX.values >= 0\n",
    "    good_Y_mask = df.pupilY.values >= 0\n",
    "    dropout_mask = good_X_mask.astype('int') + good_Y_mask.astype('int')\n",
    "    dropout_mask = dropout_mask <= 1 # Where either x or y is missing\n",
    "    # Replace these missing points with nan for now in an Nx2 array with x,y coords\n",
    "    pts_2d = df.loc[:, ['pupilX', 'pupilY']].replace(-1000, np.nan).to_numpy()\n",
    "    pts_3d = unprojectPoints(pts_2d, camera_matrix, dist_coefs, normalize=True)\n",
    "    pts_3d[dropout_mask, ] = np.nan\n",
    "    pts_3d = pd.DataFrame(pts_3d)\n",
    "    # Now the timestamps\n",
    "    times = df.loc[:, ['recordFrameCount', 'avg_fps']]\n",
    "    times['elapsed_seconds'] = get_elapsed_seconds(df['sceneQTtime(d:h:m:s.tv/ts)'].values)\n",
    "    # Save the whole video avg fps for later computation of angular velocity\n",
    "    sec_per_frame = 1/times.avg_fps.mean()\n",
    "    # Join them\n",
    "    out_df = pd.concat([times, pts_3d], axis = 1)\n",
    "    #\n",
    "    # Calculate velocity and acceleration\n",
    "    #### Extract all but the first row, and then dupl. last row, row join them (with pd.concat([],axis=0))\n",
    "    next_pts_3d = pd.concat([pts_3d.tail(-1), pts_3d.tail(1)], axis=0, ignore_index = True)\n",
    "    norm_Y = np.linalg.norm(pts_3d - next_pts_3d, axis = 1) \n",
    "    norm_X = np.linalg.norm(pts_3d + next_pts_3d, axis = 1)\n",
    "    angular_difference = 2*np.arctan2(norm_Y, norm_X)\n",
    "    angular_difference = [math.degrees(ad) for ad in angular_difference] # convert to degrees\n",
    "    # Multiplying by the frame rate (30) is equiv. to dviding by the elapsed time per frame:\n",
    "    angular_velocity = angular_difference/np.append(np.diff(times.elapsed_seconds.values), sec_per_frame);\n",
    "    #now compute angular acceleration, also doing the 0 end trick\n",
    "    angular_acceleration = np.append(np.diff(angular_velocity), 0)\n",
    "    out_df['angular_velocity'] = angular_velocity\n",
    "    out_df['angular_acceleration'] = angular_acceleration\n",
    "    out_df.to_csv(outpath,  \n",
    "                  header = ['frame', 'avg_fps', 'elapsed_seconds', 'x', 'y', 'z', 'angular_velocity', 'angular_acceleration'], \n",
    "                  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cb237d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the angular velocity and acceleration plots now that we recomputed veloc. and accel.\n",
    "# Plot velocity trace\n",
    "DF = pd.read_csv('../included/__20180817_21699/data/child/gaze_data_3dnormed_timestamped.csv')\n",
    "indexer = (DF.elapsed_seconds > 486) & (DF.elapsed_seconds < 496)\n",
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sphere_pos_over_time(DF.elapsed_seconds.values[indexer], \n",
    "                     {\"gaze velocity\": DF.angular_velocity.values[indexer]}, unit=\"deg/sec\")\n",
    "plt.title(\"Gaze velocity over time\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(DF.angular_velocity.values, bins=np.logspace(-1, np.log10(500), 50))\n",
    "plt.title(\"Gaze velocity histogram\")\n",
    "plt.xlabel(\"Gaze velocity [deg/sec]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383d0e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And for angular accel.\n",
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sphere_pos_over_time(DF.elapsed_seconds.values[indexer], \n",
    "                     {\"gaze acceleration\": DF.angular_acceleration.values[indexer]}, unit=\"deg/sec\")\n",
    "plt.title(\"Gaze Acceleration over time\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(DF.angular_acceleration.values, bins=np.logspace(-1, np.log10(500), 50))\n",
    "plt.title(\"Gaze acceleration histogram\")\n",
    "plt.xlabel(\"Gaze acceleration [deg/sec]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedb72f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And a plot with boht velocity and accel.\n",
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sphere_pos_over_time(DF.elapsed_seconds.values[indexer], \n",
    "                     {\"gaze velocity\": DF.angular_velocity.values[indexer],\n",
    "                      \"gaze acceleration\": DF.angular_acceleration.values[indexer]\n",
    "                     }, unit=\"deg/sec\")\n",
    "plt.title(\"Gaze Acceleration over time\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(DF.angular_velocity.values, bins=np.logspace(-1, np.log10(500), 50))\n",
    "plt.title(\"Gaze velocity histogram\")\n",
    "plt.xlabel(\"Gaze velocity [deg/sec]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390626b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1 = DF.shape[0]/8\n",
    "sns.lineplot(x=DF.loc[idx1:(idx1+240), 'elapsed_seconds'].values, \n",
    "             y=DF.loc[idx1:(idx1+240), 'angular_velocity'].values, \n",
    "             hue = DF.loc[idx1:(idx1+240), 'angular_velocity'].isna().cumsum(),\n",
    "            palette=['blue'] * DF.loc[idx1:(idx1+240), 'angular_velocity'].isna().cumsum().nunique(),\n",
    "            legend=False, markers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a34adf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=DF.loc[400:600, 'elapsed_seconds'].values, \n",
    "             y=DF.loc[400:600, 'angular_velocity'].values, \n",
    "             hue = DF.loc[400:600, 'angular_velocity'].isna().cumsum(),\n",
    "            palette=['blue'] * DF.loc[400:600, 'angular_velocity'].isna().cumsum().nunique(),\n",
    "            legend=False, markers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb0a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(DF.angular_velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e3a736",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(1, 9):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b980a740",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# plots of angular veloc. at different points\n",
    "#current directory: 'G:\\\\My Drive\\\\UT\\\\DIL\\\\Research\\\\EyeTrack\\\\experiment_15\\\\script_master'\n",
    "#DF = pd.read_csv('../included/__20180817_21699/data/child/gaze_data_3dnormed_timestamped.csv')\n",
    "for j in subjects:\n",
    "    datpath=f\"../included/{j}/data/child/gaze_data_3dnormed_timestamped.csv\"\n",
    "    outpath1=f\"../included/{j}/plots/child/angular_velocity.png\"\n",
    "    outpath2=f\"../angular_velocity_plots/child/{j}_angular_velocity.png\"\n",
    "    DF = pd.read_csv(datpath)\n",
    "#     tmin = DF.shape[0] / 9 # the number of rows divided into segments\n",
    "#     idx1 = (DF.elapsed_seconds > tmin) & (DF.elapsed_seconds < np.sum([tmin, 8]))\n",
    "#     idx2 = (DF.elapsed_seconds > tmin*2) & (DF.elapsed_seconds < np.sum([tmin*2, 8]))\n",
    "#     idx3 = (DF.elapsed_seconds > tmin*3) & (DF.elapsed_seconds < np.sum([tmin*3, 8]))\n",
    "#     idx4 = (DF.elapsed_seconds > tmin*4) & (DF.elapsed_seconds < np.sum([tmin*4, 8]))\n",
    "#     idx5 = (DF.elapsed_seconds > tmin*5) & (DF.elapsed_seconds < np.sum([tmin*5, 8]))\n",
    "#     idx6 = (DF.elapsed_seconds > tmin*6) & (DF.elapsed_seconds < np.sum([tmin*6, 8]))\n",
    "#     idx7 = (DF.elapsed_seconds > tmin*7) & (DF.elapsed_seconds < np.sum([tmin*7, 8]))\n",
    "#     idx8 = (DF.elapsed_seconds > tmin*8) & (DF.elapsed_seconds < np.sum([tmin*8, 8]))\n",
    "\n",
    "    idx = DF.shape[0] / 13\n",
    "    plt.figure(figsize=(24, 8))\n",
    "\n",
    "    #for i, idx in enumerate([idx1, idx2, idx3, idx4, idx5, idx6, idx7, idx8]):\n",
    "    for i in np.arange(1, 13):\n",
    "        plt.subplot(3, 4, i)\n",
    "        sns.lineplot(x=DF.loc[idx*i:idx*i+240, 'elapsed_seconds'].values, \n",
    "                     y=DF.loc[idx*i:idx*i+240, 'angular_velocity'].values, \n",
    "                     hue = DF.loc[idx*i:idx*i+240, 'angular_velocity'].isna().cumsum(),\n",
    "                     palette= [\"blue\"] * DF.loc[idx*i:idx*i+240, 'angular_velocity'].isna().cumsum().nunique(),\n",
    "                     legend=False, markers=True)\n",
    "        plt.xlabel(\"time [sec]\")\n",
    "        plt.ylabel('deg/sec')\n",
    "        #plt.legend()\n",
    "    #     sphere_pos_over_time(DF.elapsed_seconds.values[idx], \n",
    "    #                          {\"gaze velocity\": DF.angular_velocity.values[idx]}, unit=\"deg/sec\")\n",
    "        plt.suptitle(\"Gaze velocity over time\")\n",
    "        plt.subplots_adjust(left=0.1,\n",
    "                        bottom=0.1, \n",
    "                        right=0.9, \n",
    "                        top=0.9, \n",
    "                        wspace=0.4, \n",
    "                        hspace=0.4)\n",
    "    # Save plot\n",
    "    plt.savefig(outpath1)\n",
    "    plt.savefig(outpath2)\n",
    "    plt.close() # used in tandem with `%matplotlib inline`  prevents image from printing here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e750168",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Run the pipline for the parents. Both 3D projection to data frame as well as plotting and saving figs\n",
    "# Paths assumed relative to 'G:\\\\My Drive\\\\UT\\\\DIL\\\\Research\\\\EyeTrack\\\\experiment_15\\\\script_master'\n",
    "for i in subjects:\n",
    "    #datpath=f\"G:/My Drive/UT/DIL/Research/EyeTrack/experiment_15/included/{i}/data/parent_eye.txt\"\n",
    "    datpath = f\"M:/experiment_15/included/{i}/supporting_files/parent_eye.txt\"\n",
    "    DFpath=f\"../included/{i}/data/parent/gaze_data_3dnormed_timestamped.csv\"\n",
    "    outpath1=f\"../angular_velocity_plots/parent/{i}_angular_velocity.png\"\n",
    "    outpath2=f\"../included/{i}/plots/parent/angular_velocity.png\"\n",
    "    # Read in the parent_eye.txt\n",
    "#     if os.path.exists(datpath):\n",
    "#         df = pd.read_csv(datpath, header=4, sep=' ', index_col=False)\n",
    "#     else:\n",
    "#         continue # skip this person and continue to the next one\n",
    "#     good_X_mask = df.porX.values >= 0\n",
    "#     good_Y_mask = df.porY.values >= 0\n",
    "#     dropout_mask = good_X_mask.astype('int') + good_Y_mask.astype('int')\n",
    "#     dropout_mask = dropout_mask <= 1 # Where either x or y is missing\n",
    "#     # Replace these missing points with nan for now in an Nx2 array with x,y coords\n",
    "#     pts_2d = df.loc[:, ['porX', 'porY']].replace(-1000, np.nan).to_numpy()\n",
    "#     pts_3d = unprojectPoints(pts_2d, camera_matrix, dist_coefs, normalize=True)\n",
    "#     pts_3d[dropout_mask, ] = np.nan\n",
    "#     pts_3d = pd.DataFrame(pts_3d)\n",
    "#     # Now the timestamps\n",
    "#     times = df.loc[:, ['recordFrameCount', 'avg_fps']]\n",
    "#     times['elapsed_seconds'] = get_elapsed_seconds(df['sceneQTtime(d:h:m:s.tv/ts)'].values)\n",
    "#     # Save the whole video avg fps for later computation of angular velocity\n",
    "#     sec_per_frame = 1/times.avg_fps.mean()\n",
    "#     # Join them\n",
    "#     out_df = pd.concat([times, pts_3d], axis = 1)\n",
    "#     #\n",
    "#     # Calculate velocity and acceleration\n",
    "#     #### Extract all but the first row, and then dupl. last row, row join them (with pd.concat([],axis=0))\n",
    "#     next_pts_3d = pd.concat([pts_3d.tail(-1), pts_3d.tail(1)], axis=0, ignore_index = True)\n",
    "#     norm_Y = np.linalg.norm(pts_3d - next_pts_3d, axis = 1) \n",
    "#     norm_X = np.linalg.norm(pts_3d + next_pts_3d, axis = 1)\n",
    "#     angular_difference = 2*np.arctan2(norm_Y, norm_X)\n",
    "#     angular_difference = [math.degrees(ad) for ad in angular_difference] # convert to degrees\n",
    "#     # Multiplying by the frame rate (30) is equiv. to dviding by the elapsed time per frame:\n",
    "#     angular_velocity = angular_difference/np.append(np.diff(times.elapsed_seconds.values), sec_per_frame);\n",
    "#     #now compute angular acceleration, also doing the 0 end trick\n",
    "#     angular_acceleration = np.append(np.diff(angular_velocity), 0)\n",
    "#     out_df['angular_velocity'] = angular_velocity\n",
    "#     out_df['angular_acceleration'] = angular_acceleration\n",
    "#     out_df.to_csv(DFpath,  \n",
    "#                   header = ['frame', 'avg_fps', 'elapsed_seconds', \n",
    "#                             'x', 'y', 'z', 'angular_velocity', 'angular_acceleration'], \n",
    "#                   index=False)\n",
    "    # Now generate the plots\n",
    "    #DF = out_df.copy()\n",
    "    if os.path.exists(DFpath):\n",
    "        DF = pd.read_csv(DFpath)\n",
    "    else:\n",
    "        continue\n",
    "    idx = DF.shape[0] / 13\n",
    "    plt.figure(figsize=(24, 8))\n",
    "\n",
    "    for j in np.arange(1, 13):\n",
    "        plt.subplot(3, 4, j)\n",
    "        sns.lineplot(x=DF.loc[idx*j:idx*j+240, 'elapsed_seconds'].values, \n",
    "                     y=DF.loc[idx*j:idx*j+240, 'angular_velocity'].values, \n",
    "                     hue = DF.loc[idx*j:idx*j+240, 'angular_velocity'].isna().cumsum(),\n",
    "                     palette= [\"blue\"] * DF.loc[idx*j:idx*j+240, 'angular_velocity'].isna().cumsum().nunique(),\n",
    "                     legend=False, markers=True)\n",
    "        plt.xlabel(\"time [sec]\")\n",
    "        plt.ylabel('deg/sec')\n",
    "        #plt.legend()\n",
    "    #     sphere_pos_over_time(DF.elapsed_seconds.values[idx], \n",
    "    #                          {\"gaze velocity\": DF.angular_velocity.values[idx]}, unit=\"deg/sec\")\n",
    "        plt.suptitle(\"Gaze velocity over time\")\n",
    "        plt.subplots_adjust(left=0.1,\n",
    "                        bottom=0.1, \n",
    "                        right=0.9, \n",
    "                        top=0.9, \n",
    "                        wspace=0.4, \n",
    "                        hspace=0.4)\n",
    "    # Save plot\n",
    "    plt.savefig(outpath1)\n",
    "    plt.savefig(outpath2)\n",
    "    plt.close() # used in tandem with `%matplotlib inline`  prevents image from printing here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5b4aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192e2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(np.round(44001 / 13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8ff11f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sj/yj176mhx02n6shs20d029st40000gn/T/ipykernel_84787/1103355103.py:29: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pts_3d /= np.linalg.norm(pts_3d, axis=1)[:, np.newaxis]\n",
      "/Users/ianjdouglas/anaconda3/lib/python3.8/site-packages/numpy/linalg/linalg.py:2560: RuntimeWarning: overflow encountered in reduce\n",
      "  return sqrt(add.reduce(s, axis=axis, keepdims=keepdims))\n"
     ]
    }
   ],
   "source": [
    "# Repeat with smoothed data and save out a master data file with all derived and raw vars of interest\n",
    "# Now loop through subjects\n",
    "for i in subjects:\n",
    "    datpath=f\"../included/{i}/data/child/child_eye.txt\"\n",
    "    outpath=f\"../included/{i}/data/child/master_gaze.csv\"\n",
    "    # Read in the child_eye.txt\n",
    "    if os.path.exists(datpath):\n",
    "        df = pd.read_csv(datpath, header = 4, sep = ' ', index_col = False)\n",
    "    else:\n",
    "        print(f\"No child_eye.txt found at {datpath}\")\n",
    "        continue\n",
    "    pts_2d = df.loc[:, ['porX', 'porY']].to_numpy()\n",
    "    # Project points into 3d, and then re-insert np.nan\n",
    "    # Note uses unprojectPoints (pupil labs' wrapper of cv2 function)\n",
    "    pts_3d = unprojectPoints(pts_2d, camera_matrix, dist_coefs, normalize=True)\n",
    "    pts_3d_smth = pd.DataFrame(np.apply_along_axis(smooth, 0, pts_3d)) # smooth the projected points\n",
    "    pts_3d = pd.DataFrame(pts_3d)\n",
    "    pts_3d_smth = pd.DataFrame(pts_3d_smth)\n",
    "    pts_2d_smth = pts_3d_smth.iloc[:,0:2] # x and y\n",
    "    # Now repeat with smoothed data (OLD VERSION)\n",
    "    #pts_2d_smth = np.apply_along_axis(smooth, 0, pts_2d)\n",
    "    #pts_3d_smth = unprojectPoints(pts_2d_smth, camera_matrix, dist_coefs, normalize=True)\n",
    "    #pts_3d_smth =pd.DataFrame(pts_3d_smth)\n",
    "    \n",
    "    # Now convert the timestamps to elapsed seconds from strings using heper fn `get_elapsed_seconds`\n",
    "    times = df.loc[:, ['recordFrameCount', 'avg_fps']]\n",
    "    times['elapsed_seconds'] = get_elapsed_seconds(df['sceneQTtime(d:h:m:s.tv/ts)'].values)\n",
    "    # Save the whole video avg fps for later computation of angular velocity\n",
    "    sec_per_frame = 1/times.avg_fps.mean()\n",
    "    # Join them together at this point before computing derived measures\n",
    "    out_df = pd.concat([times, pts_3d, pts_3d_smth, \n",
    "                        df.loc[:, ['porX','porY']],\n",
    "                       pd.DataFrame(pts_2d_smth)], axis = 1)\n",
    "    #\n",
    "    # Calculate velocity and acceleration with smoothed and non smooth\n",
    "    #### Extract all but the first row, and then dupl. last row, row join them (with pd.concat([],axis=0))\n",
    "    next_pts_3d = pd.concat([pts_3d.tail(-1), pts_3d.tail(1)], axis=0, ignore_index = True)\n",
    "    norm_Y = np.linalg.norm(pts_3d - next_pts_3d, axis = 1) \n",
    "    norm_X = np.linalg.norm(pts_3d + next_pts_3d, axis = 1)\n",
    "    angular_difference = 2*np.arctan2(norm_Y, norm_X)\n",
    "    angular_difference = [math.degrees(ad) for ad in angular_difference] # convert to degrees\n",
    "    # Multiplying by the frame rate (30) is equiv. to dviding by the elapsed time per frame:\n",
    "    angular_velocity = angular_difference/np.append(np.diff(times.elapsed_seconds.values), sec_per_frame);\n",
    "    #now compute angular acceleration, also doing the 0 end trick\n",
    "    angular_acceleration = np.append(np.diff(angular_velocity), 0)\n",
    "    ### Repeat with smoothed points\n",
    "    next_pts_3d_smth = pd.concat([pts_3d_smth.tail(-1), pts_3d_smth.tail(1)], axis=0, ignore_index = True)\n",
    "    norm_Y_smth = np.linalg.norm(pts_3d_smth - next_pts_3d_smth, axis = 1) \n",
    "    norm_X_smth = np.linalg.norm(pts_3d_smth + next_pts_3d_smth, axis = 1)\n",
    "    angular_difference_smth = 2*np.arctan2(norm_Y_smth, norm_X_smth)\n",
    "    angular_difference_smth = [math.degrees(ad) for ad in angular_difference_smth] # convert to degrees\n",
    "    # Multiplying by the frame rate (30) is equiv. to dviding by the elapsed time per frame:\n",
    "    angular_velocity_smth = angular_difference_smth/np.append(np.diff(times.elapsed_seconds.values), sec_per_frame);\n",
    "    #now compute angular acceleration, also doing the 0 end trick\n",
    "    angular_acceleration_smth = np.append(np.diff(angular_velocity_smth), 0)\n",
    "    # Now, based on frames where angular velocity is above 700 ms, replace all values with na\n",
    "    na_idx = angular_velocity > 700\n",
    "    na_idx_smth = angular_velocity_smth > 700\n",
    "    angular_velocity[na_idx] = np.nan\n",
    "    angular_acceleration[na_idx] = np.nan\n",
    "    angular_velocity_smth[na_idx_smth] = np.nan\n",
    "    angular_acceleration_smth[na_idx_smth] = np.nan\n",
    "    # Add the derived measures\n",
    "    out_df['angular_velocity'] = angular_velocity\n",
    "    out_df['angular_acceleration'] = angular_acceleration\n",
    "    out_df['ang_vel_smoothed'] = angular_velocity_smth\n",
    "    out_df['ang_accel_smoothed'] = angular_acceleration_smth\n",
    "    # Make on additional clolumn for median filtering as a final step\n",
    "    out_df['AV_PostSmoothed'] = medfilt(angular_velocity, kernel_size = 3) # small amount of smoothing\n",
    "    # Save out the df\n",
    "    out_df.to_csv(outpath,  \n",
    "                  header = ['frame', 'avg_fps', 'elapsed_seconds', 'x_3D', 'y_3D', 'z_3D', \n",
    "                            'x_3D_smoothed', 'y_3D_smoothed', 'z_3D_smoothed',\n",
    "                            'x_2D_raw', 'y_2D_raw', 'x_2D_smoothed', 'y_2D_smoothed',\n",
    "                            'angular_velocity', 'angular_acceleration',\n",
    "                            'ang_vel_smoothed', 'ang_accel_smoothed','AV_PostSmoothed'\n",
    "                           ], \n",
    "                  index=False)\n",
    "    \n",
    "#     # Generate plots\n",
    "#     # read data back in so it has the right column names\n",
    "#     DF = pd.read_csv(outpath) \n",
    "#     # prepare filepaths for saving plots:\n",
    "#     out1=f\"../angular_velocity_plots/child/{i}_angular_velocity.png\"\n",
    "#     out2=f\"../included/{i}/plots/child/angular_velocity.png\"\n",
    "#     smth_out1=f\"../angular_velocity_plots/child/{i}_smoothed_angvel.png\"\n",
    "#     smth_out2=f\"../included/{i}/plots/child/smoothed_angvel.png\"\n",
    "    \n",
    "#     # First the angular velocity plots without smoothing\n",
    "#     idx = int(np.round(DF.shape[0] / 13)) # create 12 chunks of around 8 seconds each, evenly spaced\n",
    "#     plt.figure(figsize=(24, 8))\n",
    "#     for j in np.arange(1, 13):\n",
    "#         plt.subplot(3, 4, j)\n",
    "#         sns.lineplot(x=DF.loc[idx*j:idx*j+240, 'elapsed_seconds'].values, \n",
    "#                      y=DF.loc[idx*j:idx*j+240, 'angular_velocity'].values, \n",
    "#                      hue = DF.loc[idx*j:idx*j+240, 'angular_velocity'].isna().cumsum(),\n",
    "#                      palette= [\"blue\"] * DF.loc[idx*j:idx*j+240, 'angular_velocity'].isna().cumsum().nunique(),\n",
    "#                      legend=False, markers=True)\n",
    "#         plt.xlabel(\"time [sec]\")\n",
    "#         plt.ylabel('deg/sec')\n",
    "#         #plt.legend()\n",
    "#     #     sphere_pos_over_time(DF.elapsed_seconds.values[idx], \n",
    "#     #                          {\"gaze velocity\": DF.angular_velocity.values[idx]}, unit=\"deg/sec\")\n",
    "#         plt.suptitle(\"Gaze velocity over time; no smoothing\")\n",
    "#         plt.subplots_adjust(left=0.1,\n",
    "#                         bottom=0.1, \n",
    "#                         right=0.9, \n",
    "#                         top=0.9, \n",
    "#                         wspace=0.4, \n",
    "#                         hspace=0.4)\n",
    "#     # Save plot\n",
    "#     plt.savefig(out1)\n",
    "#     plt.savefig(out2)\n",
    "#     plt.close()\n",
    "    \n",
    "#     # Now repeat with the smoothed data\n",
    "#     idx = int(np.round(DF.shape[0] / 13)) # create 12 chunks of around 8 seconds each, evenly spaced\n",
    "#     plt.figure(figsize=(24, 8))\n",
    "#     for j in np.arange(1, 13):\n",
    "#         plt.subplot(3, 4, j)\n",
    "#         sns.lineplot(x=DF.loc[idx*j:idx*j+240, 'elapsed_seconds'].values, \n",
    "#                      y=DF.loc[idx*j:idx*j+240, 'ang_vel_smoothed'].values, \n",
    "#                      hue = DF.loc[idx*j:idx*j+240, 'ang_vel_smoothed'].isna().cumsum(),\n",
    "#                      palette= [\"blue\"] * DF.loc[idx*j:idx*j+240, 'ang_vel_smoothed'].isna().cumsum().nunique(),\n",
    "#                      legend=False, markers=True)\n",
    "#         plt.xlabel(\"time [sec]\")\n",
    "#         plt.ylabel('deg/sec')\n",
    "#         #plt.legend()\n",
    "#     #     sphere_pos_over_time(DF.elapsed_seconds.values[idx], \n",
    "#     #                          {\"gaze velocity\": DF.angular_velocity.values[idx]}, unit=\"deg/sec\")\n",
    "#         plt.suptitle(\"Gaze velocity over time; raw signals smoothed with median filter window size: 5\")\n",
    "#         plt.subplots_adjust(left=0.1,\n",
    "#                         bottom=0.1, \n",
    "#                         right=0.9, \n",
    "#                         top=0.9, \n",
    "#                         wspace=0.4, \n",
    "#                         hspace=0.4)\n",
    "#     # Save plot\n",
    "#     plt.savefig(smth_out1)\n",
    "#     plt.savefig(smth_out2)\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d85f195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No parent_eye.txt found for __20180725_21960\n"
     ]
    }
   ],
   "source": [
    "# Copying parent_eye.txt from multiwork to google drive for more stable access\n",
    "for s in subjects:\n",
    "    the_path = f\"/Volumes/multiwork/experiment_15/included/{s}/supporting_files/parent_eye.txt\"\n",
    "    dest = f'../included/{s}/data/parent/parent_eye.txt'\n",
    "    if os.path.exists(the_path):\n",
    "        #print(\"from: {};\\n to: {}\".format(the_path, dest))\n",
    "        shutil.copyfile(the_path, dest)\n",
    "    else:\n",
    "        print(f'No parent_eye.txt found for {s}')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e53fa2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sj/yj176mhx02n6shs20d029st40000gn/T/ipykernel_84787/1103355103.py:29: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pts_3d /= np.linalg.norm(pts_3d, axis=1)[:, np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No parent_eye.txt found at ../included/__20180725_21960/data/parent/parent_eye.txt\n"
     ]
    }
   ],
   "source": [
    "# Repeat for parents\n",
    "# Repeat with smoothed data and save out a master data file with all derived and raw vars of interest\n",
    "# Now loop through subjects\n",
    "for i in subjects:\n",
    "    datpath=f\"../included/{i}/data/parent/parent_eye.txt\"\n",
    "    outpath=f\"../included/{i}/data/parent/master_gaze.csv\"\n",
    "    # Read in the parent_eye.txt\n",
    "    if os.path.exists(datpath):\n",
    "        df = pd.read_csv(datpath, header = 4, sep = ' ', index_col = False)\n",
    "    else:\n",
    "        print(f\"No parent_eye.txt found at {datpath}\")\n",
    "        continue\n",
    "    pts_2d = df.loc[:, ['porX', 'porY']].to_numpy()\n",
    "    # Project points into 3d, and then re-insert np.nan\n",
    "    # Note uses unprojectPoints (pupil labs' wrapper of cv2 function)\n",
    "    pts_3d = unprojectPoints(pts_2d, camera_matrix, dist_coefs, normalize=True)\n",
    "    pts_3d_smth = pd.DataFrame(np.apply_along_axis(smooth, 0, pts_3d)) # smooth the projected points\n",
    "    pts_3d = pd.DataFrame(pts_3d)\n",
    "    pts_3d_smth = pd.DataFrame(pts_3d_smth)\n",
    "    pts_2d_smth = pts_3d_smth.iloc[:,0:2] # x and y\n",
    "    # Now repeat with smoothed data\n",
    "    #pts_2d_smth = np.apply_along_axis(smooth, 0, pts_2d)\n",
    "    #pts_3d_smth = unprojectPoints(pts_2d_smth, camera_matrix, dist_coefs, normalize=True)\n",
    "    #pts_3d_smth =pd.DataFrame(pts_3d_smth)\n",
    "    # Now convert the timestamps to elapsed seconds from strings using heper fn `get_elapsed_seconds`\n",
    "    times = df.loc[:, ['recordFrameCount', 'avg_fps']]\n",
    "    times['elapsed_seconds'] = get_elapsed_seconds(df['sceneQTtime(d:h:m:s.tv/ts)'].values)\n",
    "    # Save the whole video avg fps for later computation of angular velocity\n",
    "    sec_per_frame = 1/times.avg_fps.mean()\n",
    "    # Join them together at this point before computing derived measures\n",
    "    out_df = pd.concat([times, pts_3d, pts_3d_smth, \n",
    "                        df.loc[:, ['porX','porY']],\n",
    "                       pd.DataFrame(pts_2d_smth)], axis = 1)\n",
    "    #\n",
    "    # Calculate velocity and acceleration with smoothed and non smooth\n",
    "    #### Extract all but the first row, and then dupl. last row, row join them (with pd.concat([],axis=0))\n",
    "    next_pts_3d = pd.concat([pts_3d.tail(-1), pts_3d.tail(1)], axis=0, ignore_index = True)\n",
    "    norm_Y = np.linalg.norm(pts_3d - next_pts_3d, axis = 1) \n",
    "    norm_X = np.linalg.norm(pts_3d + next_pts_3d, axis = 1)\n",
    "    angular_difference = 2*np.arctan2(norm_Y, norm_X)\n",
    "    angular_difference = [math.degrees(ad) for ad in angular_difference] # convert to degrees\n",
    "    # Multiplying by the frame rate (30) is equiv. to dviding by the elapsed time per frame:\n",
    "    angular_velocity = angular_difference/np.append(np.diff(times.elapsed_seconds.values), sec_per_frame);\n",
    "    #now compute angular acceleration, also doing the 0 end trick\n",
    "    angular_acceleration = np.append(np.diff(angular_velocity), 0)\n",
    "    ### Repeat with smoothed points\n",
    "    next_pts_3d_smth = pd.concat([pts_3d_smth.tail(-1), pts_3d_smth.tail(1)], axis=0, ignore_index = True)\n",
    "    norm_Y_smth = np.linalg.norm(pts_3d_smth - next_pts_3d_smth, axis = 1) \n",
    "    norm_X_smth = np.linalg.norm(pts_3d_smth + next_pts_3d_smth, axis = 1)\n",
    "    angular_difference_smth = 2*np.arctan2(norm_Y_smth, norm_X_smth)\n",
    "    angular_difference_smth = [math.degrees(ad) for ad in angular_difference_smth] # convert to degrees\n",
    "    # Multiplying by the frame rate (30) is equiv. to dviding by the elapsed time per frame:\n",
    "    angular_velocity_smth = angular_difference_smth/np.append(np.diff(times.elapsed_seconds.values), sec_per_frame);\n",
    "    #now compute angular acceleration, also doing the 0 end trick\n",
    "    angular_acceleration_smth = np.append(np.diff(angular_velocity_smth), 0)\n",
    "    # Now, based on frames where angular velocity is above 700 ms, replace all values with na\n",
    "    na_idx = angular_velocity > 700\n",
    "    na_idx_smth = angular_velocity_smth > 700\n",
    "    angular_velocity[na_idx] = np.nan\n",
    "    angular_acceleration[na_idx] = np.nan\n",
    "    angular_velocity_smth[na_idx_smth] = np.nan\n",
    "    angular_acceleration_smth[na_idx_smth] = np.nan\n",
    "    # Add the derived measures\n",
    "    out_df['angular_velocity'] = angular_velocity\n",
    "    out_df['angular_acceleration'] = angular_acceleration\n",
    "    out_df['ang_vel_smoothed'] = angular_velocity_smth\n",
    "    out_df['ang_accel_smoothed'] = angular_acceleration_smth\n",
    "    # Make on additional clolumn for median filtering as a final step\n",
    "    out_df['AV_PostSmoothed'] = medfilt(angular_velocity, kernel_size = 3) # small amount of smoothing\n",
    "    # Save out the df\n",
    "    out_df.to_csv(outpath,  \n",
    "                  header = ['frame', 'avg_fps', 'elapsed_seconds', 'x_3D', 'y_3D', 'z_3D', \n",
    "                            'x_3D_smoothed', 'y_3D_smoothed', 'z_3D_smoothed',\n",
    "                            'x_2D_raw', 'y_2D_raw', 'x_2D_smoothed', 'y_2D_smoothed',\n",
    "                            'angular_velocity', 'angular_acceleration',\n",
    "                            'ang_vel_smoothed', 'ang_accel_smoothed','AV_PostSmoothed'\n",
    "                           ], \n",
    "                  index=False)\n",
    "    \n",
    "#     # Generate plots\n",
    "#     # read data back in so it has the right column names\n",
    "#     DF = pd.read_csv(outpath) \n",
    "#     # prepare filepaths for saving plots:\n",
    "#     out1=f\"../angular_velocity_plots/parent/{i}_angular_velocity.png\"\n",
    "#     out2=f\"../included/{i}/plots/parent/angular_velocity.png\"\n",
    "#     smth_out1=f\"../angular_velocity_plots/parent/{i}_smoothed_angvel.png\"\n",
    "#     smth_out2=f\"../included/{i}/plots/parent/smoothed_angvel.png\"\n",
    "    \n",
    "#     # First the angular velocity plots without smoothing\n",
    "#     idx = int(np.round(DF.shape[0] / 13)) # create 12 chunks of around 8 seconds each, evenly spaced\n",
    "#     plt.figure(figsize=(24, 8))\n",
    "#     for j in np.arange(1, 13):\n",
    "#         plt.subplot(3, 4, j)\n",
    "#         sns.lineplot(x=DF.loc[idx*j:idx*j+240, 'elapsed_seconds'].values, \n",
    "#                      y=DF.loc[idx*j:idx*j+240, 'angular_velocity'].values, \n",
    "#                      hue = DF.loc[idx*j:idx*j+240, 'angular_velocity'].isna().cumsum(),\n",
    "#                      palette= [\"blue\"] * DF.loc[idx*j:idx*j+240, 'angular_velocity'].isna().cumsum().nunique(),\n",
    "#                      legend=False, markers=True)\n",
    "#         plt.xlabel(\"time [sec]\")\n",
    "#         plt.ylabel('deg/sec')\n",
    "#         #plt.legend()\n",
    "#     #     sphere_pos_over_time(DF.elapsed_seconds.values[idx], \n",
    "#     #                          {\"gaze velocity\": DF.angular_velocity.values[idx]}, unit=\"deg/sec\")\n",
    "#         plt.suptitle(\"Gaze velocity over time; no smoothing\")\n",
    "#         plt.subplots_adjust(left=0.1,\n",
    "#                         bottom=0.1, \n",
    "#                         right=0.9, \n",
    "#                         top=0.9, \n",
    "#                         wspace=0.4, \n",
    "#                         hspace=0.4)\n",
    "#     # Save plot\n",
    "#     plt.savefig(out1)\n",
    "#     plt.savefig(out2)\n",
    "#     plt.close()\n",
    "    \n",
    "#     # Now repeat with the smoothed data\n",
    "#     idx = int(np.round(DF.shape[0] / 13)) # create 12 chunks of around 8 seconds each, evenly spaced\n",
    "#     plt.figure(figsize=(24, 8))\n",
    "#     for j in np.arange(1, 13):\n",
    "#         plt.subplot(3, 4, j)\n",
    "#         sns.lineplot(x=DF.loc[idx*j:idx*j+240, 'elapsed_seconds'].values, \n",
    "#                      y=DF.loc[idx*j:idx*j+240, 'ang_vel_smoothed'].values, \n",
    "#                      hue = DF.loc[idx*j:idx*j+240, 'ang_vel_smoothed'].isna().cumsum(),\n",
    "#                      palette= [\"blue\"] * DF.loc[idx*j:idx*j+240, 'ang_vel_smoothed'].isna().cumsum().nunique(),\n",
    "#                      legend=False, markers=True)\n",
    "#         plt.xlabel(\"time [sec]\")\n",
    "#         plt.ylabel('deg/sec')\n",
    "#         #plt.legend()\n",
    "#     #     sphere_pos_over_time(DF.elapsed_seconds.values[idx], \n",
    "#     #                          {\"gaze velocity\": DF.angular_velocity.values[idx]}, unit=\"deg/sec\")\n",
    "#         plt.suptitle(\"Gaze velocity over time; raw signals smoothed with median filter window size: 5\")\n",
    "#         plt.subplots_adjust(left=0.1,\n",
    "#                         bottom=0.1, \n",
    "#                         right=0.9, \n",
    "#                         top=0.9, \n",
    "#                         wspace=0.4, \n",
    "#                         hspace=0.4)\n",
    "#     # Save plot\n",
    "#     plt.savefig(smth_out1)\n",
    "#     plt.savefig(smth_out2)\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72325015",
   "metadata": {},
   "outputs": [],
   "source": [
    "lspace = np.linspace(0, 1242, 50)\n",
    "for j, k in enumerate(lspace):\n",
    "    if j != 1242:\n",
    "        print(j)\n",
    "        \n",
    "# Concusion: j is index starting at 0, k is value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5699bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate plots that show wide 20-second segments throughout previously determined good chunks\n",
    "# For these plots, also replace any saccades beyond 800 ms in speed with np.nan\n",
    "ratings = pd.read_csv('../noise_ratings.csv')\n",
    "cgood = np.logical_and(np.isfinite(ratings.c_good_start_sec), np.isfinite(ratings.c_good_end_sec))\n",
    "pgood = np.logical_and(np.isfinite(ratings.p_good_start_sec), np.isfinite(ratings.p_good_end_sec))\n",
    "child_keep = ratings.subject[cgood].reset_index(drop=True).values\n",
    "parent_keep = ratings.subject[pgood].reset_index(drop=True).values\n",
    "# redo plots with larger portion of time for subjects whose data are cleaner\n",
    "for i in child_keep:\n",
    "    # Read in the data\n",
    "    datpath=f\"../included/{i}/data/child/master_gaze.csv\"\n",
    "    DF = pd.read_csv(datpath) \n",
    "    # chunk out the segment of interest\n",
    "    start = ratings[ratings.subject == i].c_good_start_sec.values[0]\n",
    "    end = ratings[ratings.subject == i].c_good_end_sec.values[0]\n",
    "    df = DF[np.logical_and(DF.elapsed_seconds >= start, DF.elapsed_seconds <= end)]\n",
    "    \n",
    "    # We're gonna create 50-second chunks evenly spaced\n",
    "    sections = np.arange(start, end, 20)\n",
    "    for idx, _start in enumerate(sections):\n",
    "        if idx != len(sections)-1:\n",
    "            _end = sections[idx+1] # find the end segment\n",
    "            # figure out file paths to save plot\n",
    "            if not os.path.exists(f\"../included/{i}/plots/child/timecourses/\"):\n",
    "                os.mkdir(f\"../included/{i}/plots/child/timecourses/\")\n",
    "            out1 = f\"../included/{i}/plots/child/timecourses/timecourse_{idx+1}.png\"\n",
    "            out2 = f\"../segment_velocity_timecourses/child/{i}_timecourse_{idx+1}.png\"\n",
    "            # chunk out this segment\n",
    "            sec = df[np.logical_and(df.elapsed_seconds >= _start, df.elapsed_seconds <= _end)]\n",
    "            # Now clean up the unrealistic values\n",
    "            sec.loc[sec['angular_velocity'] > 800, 'angular_velocity'] = np.nan\n",
    "            # plot it\n",
    "            plt.figure(figsize=(16, 4))\n",
    "            if any(sec.loc[:, 'angular_velocity'].isna()):\n",
    "                sns.lineplot(x=sec.elapsed_seconds.values, \n",
    "                             y=sec.angular_velocity.values, \n",
    "                             hue = sec.loc[:, 'angular_velocity'].isna().cumsum(),\n",
    "                             palette= [\"blue\"] * sec.loc[:, 'angular_velocity'].isna().cumsum().nunique(),\n",
    "                             legend=False, markers=True)\n",
    "            else:\n",
    "                sns.lineplot(x=sec.elapsed_seconds.values, \n",
    "                             y=sec.angular_velocity.values, legend=False, markers=True)\n",
    "            plt.xlabel(\"time [sec]\")\n",
    "            plt.ylabel('deg/sec')\n",
    "            # Save plot\n",
    "            plt.savefig(out1)\n",
    "            plt.savefig(out2)\n",
    "            plt.close()\n",
    "            #print(sections); print(start); print(end); print(_start); print(_end); print(sec.head());  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ff1817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the wide timecourse plots for all subjects\n",
    "for i in subjects:\n",
    "    # Read in the data\n",
    "    datpath=f\"../included/{i}/data/child/master_gaze.csv\"\n",
    "    df = pd.read_csv(datpath) \n",
    "    \n",
    "    # figure out file paths to save plot\n",
    "    if not os.path.exists(f\"../included/{i}/plots/child/whole_timecourse/\"):\n",
    "        os.mkdir(f\"../included/{i}/plots/child/whole_timecourse/\")\n",
    "    out = f\"../included/{i}/plots/child/whole_timecourse/timecourse.png\"\n",
    "    # chunk out the segment of interest (using whole video!)\n",
    "    start = df.elapsed_seconds.min()\n",
    "    end = df.elapsed_seconds.max()\n",
    "    \n",
    "    # We're gonna create 20-second chunks evenly spaced\n",
    "    sections = np.arange(start, end, 20)\n",
    "    n_plots = len(sections) - 1\n",
    "    plt.figure(figsize=(20,4*n_plots))\n",
    "    for idx, _start in enumerate(sections):\n",
    "        if idx != len(sections)-1:\n",
    "            _end = sections[idx+1] # find the end segment\n",
    "            #out1 = f\"../included/{i}/plots/child/timecourses/timecourse_{idx+1}.png\"\n",
    "\n",
    "            # chunk out this segment\n",
    "            sec = df[np.logical_and(df.elapsed_seconds >= _start, df.elapsed_seconds <= _end)]\n",
    "            # plot it\n",
    "            #plt.figure(figsize=(18, 4))\n",
    "            plt.subplot(n_plots, 1, idx+1)\n",
    "            if any(sec.loc[:, 'angular_velocity'].isna()):\n",
    "                sns.lineplot(x=sec.elapsed_seconds.values, \n",
    "                             y=sec.angular_velocity.values, \n",
    "                             hue = sec.loc[:, 'angular_velocity'].isna().cumsum(),\n",
    "                             palette= [\"blue\"] * sec.loc[:, 'angular_velocity'].isna().cumsum().nunique(),\n",
    "                             legend=False, markers=True)\n",
    "            else:\n",
    "                sns.lineplot(x=sec.elapsed_seconds.values, \n",
    "                             y=sec.angular_velocity.values, legend=False, markers=True)\n",
    "            plt.xlabel(\"time [sec]\")\n",
    "            plt.ylabel('deg/sec')\n",
    "            # Save plot\n",
    "    plt.savefig(out, facecolor='w')\n",
    "            \n",
    "    plt.close()\n",
    "    #print(sections); print(start); print(end); print(_start); print(_end); print(sec.head()); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64fa53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in subjects[:1]:\n",
    "    # Read in the data\n",
    "    datpath=f\"../included/{i}/data/child/master_gaze.csv\"\n",
    "    df = pd.read_csv(datpath) \n",
    "    print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e32dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the wide timecourse plots for all subjects WITH SMOOTHED VELOCITY\n",
    "for i in subjects:\n",
    "    # Read in the data\n",
    "    datpath=f\"../included/{i}/data/child/master_gaze.csv\"\n",
    "    df = pd.read_csv(datpath) \n",
    "    \n",
    "    # figure out file paths to save plot\n",
    "    if not os.path.exists(f\"../included/{i}/plots/child/whole_timecourse/\"):\n",
    "        os.mkdir(f\"../included/{i}/plots/child/whole_timecourse/\")\n",
    "    out = f\"../included/{i}/plots/child/whole_timecourse/smoothed-xy2D-window5median_timecourse.png\"\n",
    "    # chunk out the segment of interest (using whole video!)\n",
    "    start = df.elapsed_seconds.min()\n",
    "    end = df.elapsed_seconds.max()\n",
    "    \n",
    "    # We're gonna create 20-second chunks evenly spaced\n",
    "    sections = np.arange(start, end, 20)\n",
    "    n_plots = len(sections) - 1\n",
    "    plt.figure(figsize=(20,4*n_plots))\n",
    "    for idx, _start in enumerate(sections):\n",
    "        if idx != len(sections)-1:\n",
    "            _end = sections[idx+1] # find the end segment\n",
    "            #out1 = f\"../included/{i}/plots/child/timecourses/timecourse_{idx+1}.png\"\n",
    "\n",
    "            # chunk out this segment\n",
    "            sec = df[np.logical_and(df.elapsed_seconds >= _start, df.elapsed_seconds <= _end)]\n",
    "            # plot it\n",
    "            #plt.figure(figsize=(18, 4))\n",
    "            plt.subplot(n_plots, 1, idx+1)\n",
    "            if any(sec.loc[:, 'ang_vel_smoothed'].isna()):\n",
    "                sns.lineplot(x=sec.elapsed_seconds.values, \n",
    "                             y=sec.ang_vel_smoothed.values, # SMOOTHED DATA\n",
    "                             hue = sec.loc[:, 'ang_vel_smoothed'].isna().cumsum(),\n",
    "                             palette= [\"blue\"] * sec.loc[:, 'ang_vel_smoothed'].isna().cumsum().nunique(),\n",
    "                             legend=False, markers=True)\n",
    "            else:\n",
    "                sns.lineplot(x=sec.elapsed_seconds.values, \n",
    "                             y=sec.ang_vel_smoothed.values, legend=False, markers=True)\n",
    "            plt.xlabel(\"time [sec]\")\n",
    "            plt.ylabel('deg/sec')\n",
    "            # Save plot\n",
    "    plt.savefig(out, facecolor='w')\n",
    "            \n",
    "    plt.close()\n",
    "    #print(sections); print(start); print(end); print(_start); print(_end); print(sec.head()); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299e18b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole timecourse for the parents (smoothed and not smoothed)\n",
    "for i in subjects:\n",
    "    # Read in the data\n",
    "    datpath=f\"../included/{i}/data/parent/master_gaze.csv\"\n",
    "    if os.path.exists(datpath):\n",
    "        df = pd.read_csv(datpath) \n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    # figure out file paths to save plot\n",
    "    if not os.path.exists(f\"../included/{i}/plots/parent/whole_timecourse/\"):\n",
    "        os.mkdir(f\"../included/{i}/plots/parent/whole_timecourse/\")\n",
    "#     out = f\"../included/{i}/plots/parent/whole_timecourse/timecourse.png\"\n",
    "#     outs = f\"../included/{i}/plots/parent/whole_timecourse/smoothed-xy2D-window5median_timecourse.png\"\n",
    "    outbox1 = f\"/Users/ianjdouglas/Box/EyeTrack/experiment_15/included/{i}/plots/parent/whole_timecourse/timecourse.png\"\n",
    "    outbox2 = f\"/Users/ianjdouglas/Box/EyeTrack/experiment_15/included/{i}/plots/parent/whole_timecourse/smoothed-xy2D-window5median_timecourse.png\"\n",
    "    paths = [f\"/Users/ianjdouglas/Box/EyeTrack/experiment_15/included/{i}\",\n",
    "             f\"/Users/ianjdouglas/Box/EyeTrack/experiment_15/included/{i}/plots\",\n",
    "             f\"/Users/ianjdouglas/Box/EyeTrack/experiment_15/included/{i}/plots/parent\",\n",
    "             f\"/Users/ianjdouglas/Box/EyeTrack/experiment_15/included/{i}/plots/parent/whole_timecourse\"]\n",
    "    for p in paths:\n",
    "        if not os.path.exists(p):\n",
    "            os.mkdir(p)\n",
    "    # chunk out the segment of interest (using whole video!)\n",
    "    start = df.elapsed_seconds.min()\n",
    "    end = df.elapsed_seconds.max()\n",
    "    \n",
    "    # We're gonna create 20-second chunks evenly spaced\n",
    "    sections = np.arange(start, end, 20)\n",
    "    n_plots = len(sections) - 1\n",
    "    # first the plots with the unsmoothed data:\n",
    "    plt.figure(figsize=(20,4*n_plots))\n",
    "    for idx, _start in enumerate(sections):\n",
    "        if idx != len(sections)-1:\n",
    "            _end = sections[idx+1] # find the end segment\n",
    "            #out1 = f\"../included/{i}/plots/child/timecourses/timecourse_{idx+1}.png\"\n",
    "\n",
    "            # chunk out this segment\n",
    "            sec = df[np.logical_and(df.elapsed_seconds >= _start, df.elapsed_seconds <= _end)]\n",
    "            # plot it\n",
    "            #plt.figure(figsize=(18, 4))\n",
    "            plt.subplot(n_plots, 1, idx+1)\n",
    "            if any(sec.loc[:, 'angular_velocity'].isna()):\n",
    "                sns.lineplot(x=sec.elapsed_seconds.values, \n",
    "                             y=sec.angular_velocity.values, # SMOOTHED DATA\n",
    "                             hue = sec.loc[:, 'angular_velocity'].isna().cumsum(),\n",
    "                             palette= [\"blue\"] * sec.loc[:, 'angular_velocity'].isna().cumsum().nunique(),\n",
    "                             legend=False, markers=True)\n",
    "            else:\n",
    "                sns.lineplot(x=sec.elapsed_seconds.values, \n",
    "                             y=sec.angular_velocity.values, legend=False, markers=True)\n",
    "            plt.xlabel(\"time [sec]\")\n",
    "            plt.ylabel('deg/sec')\n",
    "            # Save plot\n",
    "    #plt.savefig(out, facecolor='w') # not transparent so reading axis labels is easier\n",
    "    plt.savefig(outbox1, facecolor='w')\n",
    "    plt.close()\n",
    "    \n",
    "    # Now repeat with the smoothed data\n",
    "    plt.figure(figsize=(20,4*n_plots))\n",
    "    for idx, _start in enumerate(sections):\n",
    "        if idx != len(sections)-1:\n",
    "            _end = sections[idx+1] # find the end segment\n",
    "            #out1 = f\"../included/{i}/plots/child/timecourses/timecourse_{idx+1}.png\"\n",
    "\n",
    "            # chunk out this segment\n",
    "            sec = df[np.logical_and(df.elapsed_seconds >= _start, df.elapsed_seconds <= _end)]\n",
    "            # plot it\n",
    "            #plt.figure(figsize=(18, 4))\n",
    "            plt.subplot(n_plots, 1, idx+1)\n",
    "            if any(sec.loc[:, 'ang_vel_smoothed'].isna()):\n",
    "                sns.lineplot(x=sec.elapsed_seconds.values, \n",
    "                             y=sec.ang_vel_smoothed.values, # SMOOTHED DATA\n",
    "                             hue = sec.loc[:, 'ang_vel_smoothed'].isna().cumsum(),\n",
    "                             palette= [\"blue\"] * sec.loc[:, 'ang_vel_smoothed'].isna().cumsum().nunique(),\n",
    "                             legend=False, markers=True)\n",
    "            else:\n",
    "                sns.lineplot(x=sec.elapsed_seconds.values, \n",
    "                             y=sec.ang_vel_smoothed.values, legend=False, markers=True)\n",
    "            plt.xlabel(\"time [sec]\")\n",
    "            plt.ylabel('deg/sec')\n",
    "            # Save plot\n",
    "    #plt.savefig(outs, facecolor='w')\n",
    "    plt.savefig(outbox2, facecolor='w')\n",
    "            \n",
    "    plt.close()\n",
    "    #print(sections); print(start); print(end); print(_start); print(_end); print(sec.head()); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c20b40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test filter\n",
    "# sub = subjects[23]\n",
    "# print(sub)\n",
    "sub = '__20190321_21381'\n",
    "start = 734; end = 744 # define a ten second window\n",
    "datpath=f\"../included/{sub}/data/child/master_gaze.csv\"\n",
    "df = pd.read_csv(datpath)\n",
    "df = df.loc[np.logical_and(df.elapsed_seconds >= start, df.elapsed_seconds <= end), :]\n",
    "# df['angvel_SG_fltr5'] = savgol_filter(df.angular_velocity, 5, 3) # 3rd order poly\n",
    "# df['angvel_SG_fltr7'] = savgol_filter(df.angular_velocity, 7, 3) # 3rd order poly\n",
    "# df['angvel_SG_fltr11'] = savgol_filter(df.angular_velocity, 11, 3) # 3rd order poly\n",
    "# df['angvel_SG_fltr13'] = savgol_filter(df.angular_velocity, 13, 3) # 3rd order poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2c8d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from matplotlib.widgets import Slider\n",
    "# Get data for initial plot\n",
    "y_raw = df.angular_velocity.values[0:300]\n",
    "y_smoothed = savgol_filter(y_raw, 5, 3)# start with window size 5 (min with poly=3)\n",
    "time = df.elapsed_seconds.values[0:300]\n",
    "\n",
    "# create initial plot\n",
    "# sns.lineplot(x=sec.elapsed_seconds.values, \n",
    "#                              y=sec.ang_vel_smoothed.values, # SMOOTHED DATA\n",
    "#                              hue = sec.loc[:, 'ang_vel_smoothed'].isna().cumsum(),\n",
    "#                              palette= [\"blue\"] * sec.loc[:, 'ang_vel_smoothed'].isna().cumsum().nunique(),\n",
    "#                              legend=False, markers=True)\n",
    "fig = plt.figure()\n",
    "ax = fig.subplots()\n",
    "plt.subplots_adjust(bottom=.25)\n",
    "p = ax.plot(time, y_raw, 'b') \n",
    "p, = ax.plot(time, y_smoothed, 'r')\n",
    "ax.margins(x=0)\n",
    "\n",
    "# Define the slider\n",
    "ax_slide = plt.axes([0.25, .01, 0.65, 0.03]) #xposition, yposition, width and height\n",
    "# Properties of the slider\n",
    "win_size = Slider(ax_slide, 'Window size', valmin=5, valmax=39, valinit=5, valstep=2)\n",
    "\n",
    "\n",
    "def update(val):\n",
    "    current_v = win_size.val # get slider value\n",
    "    new_y = savgol_filter(y_raw, current_v, 3)\n",
    "    p.set_ydata(new_y)\n",
    "    fig.canvas.draw()\n",
    "\n",
    "# Run\n",
    "win_size.on_changed(update)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01290af6",
   "metadata": {},
   "source": [
    "# Read in the segments file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef4f7af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg = pd.read_csv('../onsets_offsets.csv', index_col=False)\n",
    "idx = ~np.logical_and(seg.loc[:, 'onsets'].isna(), seg.loc[:, 'offsets'].isna())\n",
    "s = seg.loc[idx,].reset_index(drop=True)\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43f69d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianjdouglas/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No master_gaze.csv found for __20180725_21960\n"
     ]
    }
   ],
   "source": [
    "# Make the master data frame of segments\n",
    "segments = pd.DataFrame()\n",
    "for i in s.index:\n",
    "    # scalar row indexer 1 col returns scalar\n",
    "    subj = s.loc[i, 'subject'] \n",
    "    # Read in the gaze data\n",
    "    data = pd.read_csv(f\"../included/{subj}/data/child/master_gaze.csv\", index_col=False)\n",
    "    # IF THE PARENT's DATA DOESN'T EXIST, SKIP PARTICIPANT\n",
    "    if not os.path.exists(f\"../included/{subj}/data/parent/master_gaze.csv\"):\n",
    "        print(f\"No master_gaze.csv found for {subj}\")\n",
    "        continue # then skip this pair\n",
    "        \n",
    "    # Filter segments data for this subject's segments\n",
    "    subj_seg = s.loc[[i], ['subject', 'onsets','offsets','behavior']]\n",
    "    on = re.split(';',subj_seg.onsets.values[0])\n",
    "    off = re.split(';',subj_seg.offsets.values[0])\n",
    "    beh = re.split(';', subj_seg.behavior.values[0])\n",
    "    # Loop through this subjects onsets/offsets and unnest-longer\n",
    "    subject_data = pd.DataFrame()\n",
    "    for j in range(len(on)):\n",
    "        seg_ = j\n",
    "        on_ = float(on[j])\n",
    "        off_ = float(off[j])\n",
    "        beh_ = beh[j]\n",
    "        data_ = data[data[\"elapsed_seconds\"].between(on_, off_, inclusive='both')]\n",
    "        data_.loc[:,['subject']] = subj\n",
    "        data_.loc[:,['behavior']] = beh_\n",
    "        data_.loc[:,['segment_id']] = seg_\n",
    "        subject_data = pd.concat([subject_data, data_]).reset_index(drop=True)\n",
    "    # Add this subject to the master data frame\n",
    "    segments = pd.concat([segments, subject_data]).reset_index(drop=True)\n",
    "# Write out the segmented and behavior labelled data\n",
    "segments.to_csv(\"../postureCodedSegments.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdb4f953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No master_gaze.csv found for __20180725_21960\n"
     ]
    }
   ],
   "source": [
    "# Extract the same segments from parents\n",
    "segments = pd.DataFrame()\n",
    "for i in s.index:\n",
    "    # scalar row indexer 1 col returns scalar\n",
    "    subj = s.loc[i, 'subject'] \n",
    "    # Read in the gaze data\n",
    "    # IF THE PARENT's DATA DOESN'T EXIST, SKIP PARTICIPANT\n",
    "    if not os.path.exists(f\"../included/{subj}/data/parent/master_gaze.csv\"):\n",
    "        print(f\"No master_gaze.csv found for {subj}\")\n",
    "        continue # then skip this pair\n",
    "    else:\n",
    "        data = pd.read_csv(f\"../included/{subj}/data/parent/master_gaze.csv\", index_col=False)\n",
    "    \n",
    "    # Filter segments data for this subject's segments\n",
    "    subj_seg = s.loc[[i], ['subject', 'onsets','offsets','behavior']]\n",
    "    on = re.split(';',subj_seg.onsets.values[0])\n",
    "    off = re.split(';',subj_seg.offsets.values[0])\n",
    "    #beh = re.split(';', subj_seg.behavior.values[0])\n",
    "    # Loop through this subjects onsets/offsets and unnest-longer\n",
    "    subject_data = pd.DataFrame()\n",
    "    for j in range(len(on)):\n",
    "        seg_ = j\n",
    "        on_ = float(on[j])\n",
    "        off_ = float(off[j])\n",
    "        #beh_ = beh[j]\n",
    "        data_ = data[data[\"elapsed_seconds\"].between(on_, off_, inclusive='both')]\n",
    "        data_.loc[:,['subject']] = subj\n",
    "        data_.loc[:,['behavior']] = np.nan\n",
    "        data_.loc[:,['segment_id']] = seg_\n",
    "        subject_data = pd.concat([subject_data, data_]).reset_index(drop=True)\n",
    "    # Add this subject to the master data frame\n",
    "    segments = pd.concat([segments, subject_data]).reset_index(drop=True)\n",
    "# Write out the segments from the parent data corresponding to children's data\n",
    "segments.to_csv(\"../correspondingParentSegments.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95d8768",
   "metadata": {},
   "source": [
    "### Produce the timecourse plots for the parent segments for QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccc6780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "segments = pd.read_csv('../correspondingParentSegments.csv', index_col=False)\n",
    "seg_sub = segments.subject.unique()\n",
    "for subid in seg_sub:\n",
    "#def plot_timecourse(subid):\n",
    "    seg = segments[segments.subject == subid]\n",
    "    for i in seg.segment_id.unique():\n",
    "        df = seg[seg.segment_id == i]\n",
    "        # chunk out the segment of interest (using whole video!)\n",
    "        start = df.elapsed_seconds.min()\n",
    "        end = df.elapsed_seconds.max()\n",
    "        \n",
    "        # We're gonna create 20-second chunks evenly spaced IF POSSIBLE\n",
    "        sections = np.arange(start, end, 20)\n",
    "        if len(sections) == 1:\n",
    "            # if not possible (section is less than 20 seconds long)\n",
    "            sections = np.array((start, end))\n",
    "        n_plots = len(sections) - 1\n",
    "        \n",
    "        # Generate plot\n",
    "        plt.figure(figsize=(20,4*n_plots))\n",
    "        for idx, _start in enumerate(sections):\n",
    "            if idx != len(sections)-1:\n",
    "                _end = sections[idx+1] # find the end segment\n",
    "                #out1 = f\"../included/{i}/plots/child/timecourses/timecourse_{idx+1}.png\"\n",
    "\n",
    "                # chunk out this segment\n",
    "                sec = df[df['elapsed_seconds'].between(_start, _end, inclusive = 'both')]\n",
    "                # plot it\n",
    "                #plt.figure(figsize=(18, 4))\n",
    "                plt.subplot(n_plots, 1, idx+1)\n",
    "                if any(sec.loc[:, 'angular_velocity'].isna()):\n",
    "                    sns.lineplot(x=sec.elapsed_seconds.values, \n",
    "                                 y=sec.angular_velocity.values,\n",
    "                                 hue = sec.loc[:, 'angular_velocity'].isna().cumsum(),\n",
    "                                 palette= [\"blue\"] * sec.loc[:, 'angular_velocity'].isna().cumsum().nunique(),\n",
    "                                 legend=False, markers=True)\n",
    "                else:\n",
    "                    sns.lineplot(x=sec.elapsed_seconds.values, \n",
    "                                 y=sec.angular_velocity.values, legend=False, markers=True)\n",
    "                plt.xlabel(\"time [sec]\")\n",
    "                plt.ylabel('deg/sec')\n",
    "                # Save plot\n",
    "                \n",
    "        #plt.savefig(out, facecolor='w') # not transparent so reading axis labels is easier\n",
    "        if not os.path.exists(f'../postureCodedVelocityPlots/parent/{subid}'):\n",
    "            shutil.os.mkdir(f\"../postureCodedVelocityPlots/parent/{subid}\")\n",
    "        plt.savefig(f\"../postureCodedVelocityPlots/parent/{subid}/segment_id-{i}.png\", facecolor='w')\n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
